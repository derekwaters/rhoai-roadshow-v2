{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5ecd807-fb1c-41eb-a948-365e57396d90",
   "metadata": {},
   "source": [
    "# Level 4: Agents & MCP Tools\n",
    "\n",
    "This notebook is for developers who are already familiar with [basic agent workflows](Level2_simple_agent_with_websearch.ipynb). \n",
    "Here, we will highlight more advanced use cases for agents where a single tool call is insufficient to complete the required task.\n",
    "\n",
    "We will also use [MCP tools](https://github.com/modelcontextprotocol/servers) (which can be deployed onto an OpenShift cluster) throughout this demo to show users how to extend their agents beyond Llama Stacks's current builtin tools and connect to many different services and data sources to build their own custom agents.  \n",
    "\n",
    "### Agent Example:\n",
    "\n",
    "This notebook will walkthrough how to build a system that can answer the following question via an agent built with Llama Stack:\n",
    "\n",
    "- *\"Review OpenShift logs for the failing-pod. Categorize each as either ‚ÄòNormal‚Äô or ‚ÄòError‚Äô. If it's an error search for a solution. Summarize any errors found.\"*\n",
    "\n",
    "### MCP Tools:\n",
    "\n",
    "#### OpenShift MCP Server\n",
    "\n",
    "Throughout this notebook we will be relying on the [kuberenetes-mcp-server](https://github.com/manusa/kubernetes-mcp-server) by [manusa](https://github.com/manusa) to interact with our OpenShift cluster. Please see installation instructions below if you do not already have this deployed in your environment. \n",
    "\n",
    "* [OpenShift MCP application installation](https://github.com/eformat/rhoai-policy-collection/tree/main/gitops/applications/mcp-openshift)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77a6454",
   "metadata": {},
   "source": [
    "## Pre-Requisites\n",
    "\n",
    "Before starting this notebook, ensure that you have:\n",
    "- Followed the instructions in the [Setup Guide](./Level0_getting_started_with_Llama_Stack.ipynb) notebook.\n",
    "- Access to an OpeShift cluster with a deployment of the [OpenShift MCP server](https://github.com/eformat/rhoai-policy-collection/tree/main/gitops/applications/mcp-openshift).\n",
    "- A Tavily API key is required. You can register for one at https://app.tavily.com/home.\n",
    "\n",
    "Add your TAVILY_SEARCH_API_KEY=\"tvly-dev-your-key\" to the `env.example` file.\n",
    "\n",
    "## Setting Up this Notebook\n",
    "We will initialize our environment as described in detail in our [\"Getting Started\" notebook](./Level1_getting_started_with_Llama_Stack.ipynb). Please refer to it for additional explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bafea86a-fcb4-4e69-8a73-1839b536b54d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Llama Stack server\n",
      "Inference Parameters:\n",
      "\tModel: llama3-2-3b\n",
      "\tSampling Parameters: {'strategy': {'type': 'greedy'}, 'max_tokens': 5000}\n",
      "\tstream: False\n"
     ]
    }
   ],
   "source": [
    "# for accessing the environment variables\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# for communication with Llama Stack\n",
    "from llama_stack_client import LlamaStackClient\n",
    "from llama_stack_client import Agent\n",
    "from llama_stack_client.lib.agents.react.agent import ReActAgent\n",
    "from llama_stack_client.lib.agents.react.tool_parser import ReActOutput\n",
    "from llama_stack_client.lib.agents.event_logger import EventLogger\n",
    "\n",
    "# pretty print of the results returned from the model/agent\n",
    "from termcolor import cprint\n",
    "import sys\n",
    "sys.path.append('.')\n",
    "from src.utils import step_printer\n",
    "\n",
    "base_url = os.getenv(\"REMOTE_BASE_URL\")\n",
    "\n",
    "\n",
    "# Tavily search API key is required for some of our demos and must be provided to the client upon initialization.\n",
    "# We will cover it in the agentic demos that use the respective tool. Please ignore this parameter for all other demos.\n",
    "tavily_search_api_key = os.getenv(\"TAVILY_SEARCH_API_KEY\")\n",
    "if len(tavily_search_api_key) != 41:\n",
    "    raise ValueError(\"Sorry your Tavily Search key seems invalid?\")\n",
    "else:\n",
    "    provider_data = {\"tavily_search_api_key\": tavily_search_api_key}\n",
    "\n",
    "\n",
    "client = LlamaStackClient(\n",
    "    base_url=base_url,\n",
    "    provider_data=provider_data\n",
    ")\n",
    "\n",
    "print(f\"Connected to Llama Stack server\")\n",
    "\n",
    "# model_id for the model you wish to use that is configured with the Llama Stack server\n",
    "model_id = \"llama3-2-3b\" # \"deepseek-r1-0528-qwen3-8b-bnb-4bit\"\n",
    "\n",
    "temperature = float(os.getenv(\"TEMPERATURE\", 0.0))\n",
    "if temperature > 0.0:\n",
    "    top_p = float(os.getenv(\"TOP_P\", 0.95))\n",
    "    strategy = {\"type\": \"top_p\", \"temperature\": temperature, \"top_p\": top_p}\n",
    "else:\n",
    "    strategy = {\"type\": \"greedy\"}\n",
    "\n",
    "max_tokens = 5000\n",
    "\n",
    "# sampling_params will later be used to pass the parameters to Llama Stack Agents/Inference APIs\n",
    "sampling_params = {\n",
    "    \"strategy\": strategy,\n",
    "    \"max_tokens\": max_tokens,\n",
    "}\n",
    "\n",
    "stream = False\n",
    "\n",
    "print(f\"Inference Parameters:\\n\\tModel: {model_id}\\n\\tSampling Parameters: {sampling_params}\\n\\tstream: {stream}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66044170",
   "metadata": {},
   "source": [
    "## Validate tools are available in our Llama Stack instance\n",
    "\n",
    "When an instance of Llama Stack is redeployed, it may be the case that the tools will need to be re-registered. Also if a tool is already registered with a Llama Stack instance, trying to register another one with the same `toolgroup_id` will throw you an error.\n",
    "\n",
    "For this reason, it is recommended to validate your tools and toolgroups. The following code will check that both the `builtin::websearch` and `mcp::openshift` tools are correctly registered, and if not it will attempt to register them using their specific endpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2cedaf-522b-4251-886a-d8aa7b9fcd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your Llama Stack server is registered with the following tool groups @ {'mcp::weather', 'builtin::rag', 'mcp::openshift', 'builtin::websearch', 'mcp::fast-mcp-tools', 'mcp::github'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ocp_mcp_url = os.getenv(\"REMOTE_OCP_MCP_URL\")\n",
    "\n",
    "registered_tools = client.tools.list()\n",
    "registered_toolgroups = [t.toolgroup_id for t in registered_tools]\n",
    "if \"mcp::openshift\" not in registered_toolgroups:\n",
    "    client.toolgroups.register(\n",
    "        toolgroup_id=\"mcp::openshift\",\n",
    "        provider_id=\"model-context-protocol\",\n",
    "        mcp_endpoint={\"uri\":ocp_mcp_url},\n",
    "    )\n",
    "\n",
    "print(f\"Your Llama Stack server is registered with the following tool groups @ {set(registered_toolgroups)} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa880bbc-bf69-4777-9417-ef7b13d51785",
   "metadata": {},
   "source": [
    "## Defining our Agent - Prompt Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "757508bc-a3b8-493e-b003-6d9840597ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prompt= \"\"\"You are a helpful assistant. You have access to a number of tools.\n",
    "Whenever a tool is called, be sure to return the Response in a friendly and helpful tone.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec288b9-ed91-4ff3-b8e8-77720064d4af",
   "metadata": {},
   "source": [
    "### Deploy a namespace\n",
    "\n",
    "Let's first create a namespace on the OpenShift cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29d1d1e8-b2e3-4a4c-953d-a69bc2e7d54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 1: InferenceStep ----------\n",
      "üõ†Ô∏è Tool call Generated:\n",
      "\u001b[35mTool call: namespace_create, Arguments: {'namespace': 'test'}\u001b[0m\n",
      "\n",
      "---------- üìç Step 2: ToolExecutionStep ----------\n",
      "üîß Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'test'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m, \u001b[32m'text'\u001b[0m: \u001b[32m'test'\u001b[0m, \u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 3: InferenceStep ----------\n",
      "ü§ñ Model Response:\n",
      "\u001b[35mThe namespace \"test\" has been successfully created in your cluster. You can now use this namespace for your Kubernetes resources. If you need to delete the namespace, you can use the `namespace_delete` function.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model= model_id,  # replace this with model_id to get the value of INFERENCE_MODEL_ID environment variable\n",
    "    instructions = model_prompt , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "user_prompts = [\"Create namespace called test in our cluster\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_Slack_demo\")\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream,\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b32f2bb-d003-4347-b545-ad95da1dacff",
   "metadata": {},
   "source": [
    "### Deploy a pod with simulated error logs\n",
    "\n",
    "For the purpose of testing and retrieving logs from a pod exhibiting errors, we will deploy a pod on an OpenShift cluster that produces simulated error logs. We have a pre-built container image available for this \"fake\" error pod that you can use. With the help of the agent and the OpenShift MCP server we can deploy the pod as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0e66d9-05b3-432e-b416-f63001b08704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 1: InferenceStep ----------\n",
      "üõ†Ô∏è Tool call Generated:\n",
      "\u001b[35mTool call: pods_run, Arguments: {'image': 'quay.io/redhat-et/failing-test-pod:latest', 'name': 'slack-test', 'namespace': 'test'}\u001b[0m\n",
      "\n",
      "---------- üìç Step 2: ToolExecutionStep ----------\n",
      "üîß Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'# The following resources (YAML) have been created or updated successfully\\n- apiVersion: v1\\n  kind: Pod\\n  metadata:\\n    annotations:\\n      openshift.io/scc: anyuid\\n    creationTimestamp: \"2025-06-21T08:00:01Z\"\\n    labels:\\n      app.kubernetes.io/component: slack-test\\n      app.kubernetes.io/managed-by: kubernetes-mcp-server\\n      app.kubernetes.io/name: slack-test\\n      app.kubernetes.io/part-of: kubernetes-mcp-server-run-sandbox\\n    name: slack-test\\n    namespace: test\\n    resourceVersion: \"65390143\"\\n    uid: 57e26f38-1881-4bd2-a68a-8b897f68dc59\\n  spec:\\n    containers:\\n    - image: quay.io/redhat-et/failing-test-pod:latest\\n      imagePullPolicy: Always\\n      name: slack-test\\n      resources: {}\\n      securityContext:\\n        capabilities:\\n          drop:\\n          - MKNOD\\n      terminationMessagePath: /dev/termination-log\\n      terminationMessagePolicy: File\\n      volumeMounts:\\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\\n        name: kube-api-access-7s8g6\\n        readOnly: true\\n    dnsPolicy: ClusterFirst\\n    enableServiceLinks: true\\n    imagePullSecrets:\\n    - name: default-dockercfg-592nq\\n    preemptionPolicy: PreemptLowerPriority\\n    priority: 0\\n    restartPolicy: Always\\n    schedulerName: default-scheduler\\n    securityContext:\\n      seLinuxOptions:\\n        level: s0:c35,c0\\n    serviceAccount: default\\n    serviceAccountName: default\\n    terminationGracePeriodSeconds: 30\\n    tolerations:\\n    - effect: NoExecute\\n      key: node.kubernetes.io/not-ready\\n      operator: Exists\\n      tolerationSeconds: 300\\n    - effect: NoExecute\\n      key: node.kubernetes.io/unreachable\\n      operator: Exists\\n      tolerationSeconds: 300\\n    volumes:\\n    - name: kube-api-access-7s8g6\\n      projected:\\n        defaultMode: 420\\n        sources:\\n        - serviceAccountToken:\\n            expirationSeconds: 3607\\n            path: token\\n        - configMap:\\n            items:\\n            - key: ca.crt\\n              path: ca.crt\\n            name: kube-root-ca.crt\\n        - downwardAPI:\\n            items:\\n            - fieldRef:\\n                apiVersion: v1\\n                fieldPath: metadata.namespace\\n              path: namespace\\n        - configMap:\\n            items:\\n            - key: service-ca.crt\\n              path: service-ca.crt\\n            name: openshift-service-ca.crt\\n  status:\\n    phase: Pending\\n    qosClass: BestEffort\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'# The following resources \u001b[0m\u001b[32m(\u001b[0m\u001b[32mYAML\u001b[0m\u001b[32m)\u001b[0m\u001b[32m have been created or updated successfully\\n- apiVersion: v1\\n  kind: Pod\\n  metadata:\\n    annotations:\\n      openshift.io/scc: anyuid\\n    creationTimestamp: \"2025-06-21T08:00:01Z\"\\n    labels:\\n      app.kubernetes.io/component: slack-test\\n      app.kubernetes.io/managed-by: kubernetes-mcp-server\\n      app.kubernetes.io/name: slack-test\\n      app.kubernetes.io/part-of: kubernetes-mcp-server-run-sandbox\\n    name: slack-test\\n    namespace: test\\n    resourceVersion: \"65390143\"\\n    uid: 57e26f38-1881-4bd2-a68a-8b897f68dc59\\n  spec:\\n    containers:\\n    - image: quay.io/redhat-et/failing-test-pod:latest\\n      imagePullPolicy: Always\\n      name: slack-test\\n      resources: \u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\n      securityContext:\\n        capabilities:\\n          drop:\\n          - MKNOD\\n      terminationMessagePath: /dev/termination-log\\n      terminationMessagePolicy: File\\n      volumeMounts:\\n      - mountPath: /var/run/secrets/kubernetes.io/serviceaccount\\n        name: kube-api-access-7s8g6\\n        readOnly: true\\n    dnsPolicy: ClusterFirst\\n    enableServiceLinks: true\\n    imagePullSecrets:\\n    - name: default-dockercfg-592nq\\n    preemptionPolicy: PreemptLowerPriority\\n    priority: 0\\n    restartPolicy: Always\\n    schedulerName: default-scheduler\\n    securityContext:\\n      seLinuxOptions:\\n        level: s0:c35,c0\\n    serviceAccount: default\\n    serviceAccountName: default\\n    terminationGracePeriodSeconds: 30\\n    tolerations:\\n    - effect: NoExecute\\n      key: node.kubernetes.io/not-ready\\n      operator: Exists\\n      tolerationSeconds: 300\\n    - effect: NoExecute\\n      key: node.kubernetes.io/unreachable\\n      operator: Exists\\n      tolerationSeconds: 300\\n    volumes:\\n    - name: kube-api-access-7s8g6\\n      projected:\\n        defaultMode: 420\\n        sources:\\n        - serviceAccountToken:\\n            expirationSeconds: 3607\\n            path: token\\n        - configMap:\\n            items:\\n            - key: ca.crt\\n              path: ca.crt\\n            name: kube-root-ca.crt\\n        - downwardAPI:\\n            items:\\n            - fieldRef:\\n                apiVersion: v1\\n                fieldPath: metadata.namespace\\n              path: namespace\\n        - configMap:\\n            items:\\n            - key: service-ca.crt\\n              path: service-ca.crt\\n            name: openshift-service-ca.crt\\n  status:\\n    phase: Pending\\n    qosClass: BestEffort\\n'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 3: InferenceStep ----------\n",
      "ü§ñ Model Response:\n",
      "\u001b[35mThe pod \"slack-test\" has been successfully created in the namespace \"test\" using the \"quay.io/redhat-et/failing-test-pod:latest\" image. The pod is currently in the \"Pending\" phase and will be executed once it is ready. You can check the status of the pod by running the command `kubectl get pod slack-test -n test`.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model= model_id,  # replace this with model_id to get the value of INFERENCE_MODEL_ID environment variable\n",
    "    instructions = model_prompt , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "user_prompts = [\"Run a pod called slack-test in namespace test using the quay.io/redhat-et/failing-test-pod:latest image\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_Slack_demo\")\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream,\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfa2fb3-3d7c-40b0-aa6a-99a8ab8217d4",
   "metadata": {},
   "source": [
    "You should see a pod `slack-test` successfully deployed in your namespace on the OpenShift cluster. If you view the logs of the pod, you should see the simulated error message as follows:\n",
    "```\n",
    "Starting container...\n",
    "Failure: Unknown Error\n",
    "Error details: Container failed due to an unexpected issue during startup.\n",
    "Potential cause: Missing dependencies, configuration errors, or permission issues.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f59216-5a02-42ed-bb4c-b062136206da",
   "metadata": {},
   "source": [
    "### Retrieve logs for erroneous pods running on OpenShift and send a message to Slack\n",
    "\n",
    "Now that we have a simulated erroneous pod running on the OpenShift cluster, we can task the agent with summarizing the logs and sending a message to Slack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc7957e4-581c-4c3d-aee7-b8e3d9f2d0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 1: InferenceStep ----------\n",
      "üõ†Ô∏è Tool call Generated:\n",
      "\u001b[35mTool call: pods_log, Arguments: {'container': 'slack-test', 'name': 'slack-test', 'namespace': 'test'}\u001b[0m\n",
      "\n",
      "---------- üìç Step 2: ToolExecutionStep ----------\n",
      "üîß Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 3: InferenceStep ----------\n",
      "ü§ñ Model Response:\n",
      "\u001b[35mThe logs for the pod \"slack-test\" in the \"test\" namespace have been retrieved. Unfortunately, the logs indicate that the container \"slack-test\" experienced an error during startup, categorized as a normal error. The error message suggests that there may be missing dependencies, configuration errors, or permission issues. If you'd like, I can try to help you investigate further or provide guidance on how to resolve the issue.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n",
      "\n",
      "---------- üìç Step 1: InferenceStep ----------\n",
      "üõ†Ô∏è Tool call Generated:\n",
      "\u001b[35mTool call: pods_log, Arguments: {'container': 'slack-test', 'name': 'slack-test', 'namespace': 'test'}\u001b[0m\n",
      "\n",
      "---------- üìç Step 2: ToolExecutionStep ----------\n",
      "üîß Executing tool...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'type'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'text'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">‚îÇ   </span><span style=\"color: #008000; text-decoration-color: #008000\">'annotations'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "<span style=\"font-weight: bold\">}</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'type'\u001b[0m: \u001b[32m'text'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'text'\u001b[0m: \u001b[32m'Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n'\u001b[0m,\n",
       "\u001b[2;32m‚îÇ   \u001b[0m\u001b[32m'annotations'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "\u001b[1m}\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------- üìç Step 3: InferenceStep ----------\n",
      "ü§ñ Model Response:\n",
      "\u001b[35mThe pod \"slack-test\" in the \"test\" namespace experienced an error during startup, categorized as an error. The error message suggests that there may be missing dependencies, configuration errors, or permission issues.\n",
      "\u001b[0m\n",
      "========== Query processing completed ========== \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create simple agent with tools\n",
    "agent = Agent(\n",
    "    client,\n",
    "    model= model_id,  # replace this with model_id to get the value of INFERENCE_MODEL_ID environment variable\n",
    "    instructions = model_prompt , # update system prompt based on the model you are using\n",
    "    tools=[\"mcp::openshift\"],\n",
    "    tool_config={\"tool_choice\":\"auto\"},\n",
    "    sampling_params=sampling_params\n",
    ")\n",
    "\n",
    "user_prompts = [\"View the logs for the pod slack-test which has a single container slack-test in the test namespace. Categorize it as normal or error.\",\n",
    "               \"Summarize the results with the pod name, category along with a briefly explanation as to why you categorized it as normal or error.\"]\n",
    "session_id = agent.create_session(session_name=\"OCP_Slack_demo\")\n",
    "\n",
    "for i, prompt in enumerate(user_prompts):\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\":\"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream,\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a41f3a7",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Lets step through the output to further understands whats happening in this notebook.\n",
    "\n",
    "1. First the LLM generated a tool call for the `pods_log` tool included in the **OpenShift MCP server** and fetched the logs for the specified pod.\n",
    "2. The tool successfully retrieved the logs for the pod.\n",
    "3. The LLM  then received the logs from the tool call, along with the original query.\n",
    "4. This context was then passed back to the LLM for the final inference. The inference result provided a summary of the pod logs along with its category of 'Normal' or 'Error'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea60a1b9",
   "metadata": {},
   "source": [
    "## Defining our Agent - ReAct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd7dbe5",
   "metadata": {},
   "source": [
    "Now that we've shown that we can successfully accomplish this multi-step multi-tool task using prompt chaining, let's see if we can give our agent a bit more autonomy to perform the same task but with a single prompt instead of a chain. To do this, we will instantiate a **ReAct agent** (which is included in the llama stack python client by default).The ReAct agent is a variant of the simple agent but with the ability to loop through \"Reason then Act\" iterations, thinking through the problem and then using tools until it determines that it's task has been completed successfully.  \n",
    "\n",
    "Unlike prompt chaining which follows fixed steps, ReAct dynamically breaks down tasks and adapts its approach based on the results of each step. This makes it more flexible and capable of handling complex, real-world queries effectively.\n",
    "\n",
    "Below you will see the slight differences in the agent definition and the prompt used to accomplish our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d50e9f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "\u001b[34mProcessing user query: Review the OpenShift logs for the pod 'slack-test' with a container of the same name,in the 'test' namespace.\"\n",
      "                If the logs indicate an error search for the top OpenShift solution. Create a summary message with the category and explanation of the error.\u001b[0m\n",
      "==================================================\n",
      "\u001b[33minference> \u001b[0m\u001b[33m{\n",
      "\n",
      "\u001b[0m\u001b[33m   \u001b[0m\u001b[33m \"\u001b[0m\u001b[33mthought\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mI\u001b[0m\u001b[33m need\u001b[0m\u001b[33m to\u001b[0m\u001b[33m review\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m '\u001b[0m\u001b[33mslack\u001b[0m\u001b[33m-test\u001b[0m\u001b[33m'\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m'\u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m.\u001b[0m\u001b[33m First\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m should\u001b[0m\u001b[33m get\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m from\u001b[0m\u001b[33m the\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Then\u001b[0m\u001b[33m,\u001b[0m\u001b[33m if\u001b[0m\u001b[33m there\u001b[0m\u001b[33m's\u001b[0m\u001b[33m an\u001b[0m\u001b[33m error\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m need\u001b[0m\u001b[33m to\u001b[0m\u001b[33m search\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m top\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m solution\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Finally\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m will\u001b[0m\u001b[33m create\u001b[0m\u001b[33m a\u001b[0m\u001b[33m summary\u001b[0m\u001b[33m message\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m will\u001b[0m\u001b[33m start\u001b[0m\u001b[33m by\u001b[0m\u001b[33m getting\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m using\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mp\u001b[0m\u001b[33mods\u001b[0m\u001b[33m_log\u001b[0m\u001b[33m'\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m.\",\n",
      "\u001b[0m\u001b[33m   \u001b[0m\u001b[33m \"\u001b[0m\u001b[33maction\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m {\n",
      "\u001b[0m\u001b[33m       \u001b[0m\u001b[33m \"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_name\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mp\u001b[0m\u001b[33mods\u001b[0m\u001b[33m_log\u001b[0m\u001b[33m\",\n",
      "\u001b[0m\u001b[33m       \u001b[0m\u001b[33m \"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_params\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m [\n",
      "\u001b[0m\u001b[33m           \u001b[0m\u001b[33m {\"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mcontainer\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mvalue\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mslack\u001b[0m\u001b[33m-test\u001b[0m\u001b[33m\"},\n",
      "\u001b[0m\u001b[33m           \u001b[0m\u001b[33m {\"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mvalue\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mslack\u001b[0m\u001b[33m-test\u001b[0m\u001b[33m\"},\n",
      "\u001b[0m\u001b[33m           \u001b[0m\u001b[33m {\"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mnamespace\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mvalue\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m\"}\n",
      "\u001b[0m\u001b[33m       \u001b[0m\u001b[33m ]\n",
      "\u001b[0m\u001b[33m   \u001b[0m\u001b[33m },\n",
      "\u001b[0m\u001b[33m   \u001b[0m\u001b[33m \"\u001b[0m\u001b[33manswer\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m null\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33m}\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m\u001b[32mtool_execution> Tool:pods_log Response:{\"type\":\"text\",\"text\":\"Starting container...\\nFailure: Unknown Error\\nError details: Container failed due to an unexpected issue during startup.\\nPotential cause: Missing dependencies, configuration errors, or permission issues.\\n\",\"annotations\":null}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m{\"\u001b[0m\u001b[33mthought\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mThe\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m show\u001b[0m\u001b[33m an\u001b[0m\u001b[33m error\u001b[0m\u001b[33m:\u001b[0m\u001b[33m '\u001b[0m\u001b[33mContainer\u001b[0m\u001b[33m failed\u001b[0m\u001b[33m due\u001b[0m\u001b[33m to\u001b[0m\u001b[33m an\u001b[0m\u001b[33m unexpected\u001b[0m\u001b[33m issue\u001b[0m\u001b[33m during\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m.'\u001b[0m\u001b[33m I\u001b[0m\u001b[33m need\u001b[0m\u001b[33m to\u001b[0m\u001b[33m search\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m top\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m solution\u001b[0m\u001b[33m for\u001b[0m\u001b[33m this\u001b[0m\u001b[33m error\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m will\u001b[0m\u001b[33m use\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mbr\u001b[0m\u001b[33mave\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m'\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m to\u001b[0m\u001b[33m search\u001b[0m\u001b[33m the\u001b[0m\u001b[33m web\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m error\u001b[0m\u001b[33m.\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33maction\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m {\"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_name\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mbr\u001b[0m\u001b[33mave\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_params\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m [{\"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mquery\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mvalue\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mOpen\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m container\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m error\u001b[0m\u001b[33m\"}\u001b[0m\u001b[33m]},\u001b[0m\u001b[33m \"\u001b[0m\u001b[33manswer\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m null\u001b[0m\u001b[33m}\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:brave_search Response:Unknown tool `brave_search` was called.\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m{\"\u001b[0m\u001b[33mthought\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mI\u001b[0m\u001b[33m see\u001b[0m\u001b[33m that\u001b[0m\u001b[33m the\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m '\u001b[0m\u001b[33mbr\u001b[0m\u001b[33mave\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m'\u001b[0m\u001b[33m is\u001b[0m\u001b[33m not\u001b[0m\u001b[33m available\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Looking\u001b[0m\u001b[33m back\u001b[0m\u001b[33m at\u001b[0m\u001b[33m the\u001b[0m\u001b[33m tools\u001b[0m\u001b[33m,\u001b[0m\u001b[33m I\u001b[0m\u001b[33m have\u001b[0m\u001b[33m '\u001b[0m\u001b[33mweb\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m'\u001b[0m\u001b[33m available\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m should\u001b[0m\u001b[33m use\u001b[0m\u001b[33m '\u001b[0m\u001b[33mweb\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m'\u001b[0m\u001b[33m instead\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m error\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m is\u001b[0m\u001b[33m '\u001b[0m\u001b[33mContainer\u001b[0m\u001b[33m failed\u001b[0m\u001b[33m due\u001b[0m\u001b[33m to\u001b[0m\u001b[33m an\u001b[0m\u001b[33m unexpected\u001b[0m\u001b[33m issue\u001b[0m\u001b[33m during\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m.'\u001b[0m\u001b[33m I\u001b[0m\u001b[33m need\u001b[0m\u001b[33m to\u001b[0m\u001b[33m search\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m top\u001b[0m\u001b[33m Open\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m solution\u001b[0m\u001b[33m for\u001b[0m\u001b[33m this\u001b[0m\u001b[33m error\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m will\u001b[0m\u001b[33m use\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mweb\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m'\u001b[0m\u001b[33m tool\u001b[0m\u001b[33m to\u001b[0m\u001b[33m search\u001b[0m\u001b[33m the\u001b[0m\u001b[33m web\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m error\u001b[0m\u001b[33m.\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33maction\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m {\"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_name\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mweb\u001b[0m\u001b[33m_search\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mtool\u001b[0m\u001b[33m_params\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m [{\"\u001b[0m\u001b[33mname\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mquery\u001b[0m\u001b[33m\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mvalue\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mOpen\u001b[0m\u001b[33mShift\u001b[0m\u001b[33m container\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m error\u001b[0m\u001b[33m\"}\u001b[0m\u001b[33m]},\u001b[0m\u001b[33m \"\u001b[0m\u001b[33manswer\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m null\u001b[0m\u001b[33m}\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[32mtool_execution> Tool:web_search Response:{\"query\": \"OpenShift container startup error\", \"top_k\": [{\"title\": \"Pods fail with \\\"CreateContainerError\\\" error and \\\"executable file not ...\", \"url\": \"https://access.redhat.com/solutions/5972661\", \"content\": \"Environment Red Hat OpenShift Container Platform (RHOCP) 4 Issue Pods are unable to start and stays in a \\\"CreateContainerError\\\" status\", \"score\": 0.7144891, \"raw_content\": null}, {\"title\": \"Openshift command terminated with non-zero exit code: Error executing ...\", \"url\": \"https://stackoverflow.com/questions/55091144/openshift-command-terminated-with-non-zero-exit-code-error-executing-in-docker\", \"content\": \"I am running an opencpu based image on openshift, every time the pod starts, after just a few seconds, it crashes with the error: command terminated with non-zero exit code: Error executing in Docker Container: 137\", \"score\": 0.54346967, \"raw_content\": null}, {\"title\": \"Chapter 5. Troubleshooting | Support | OpenShift Container Platform | 4 ...\", \"url\": \"https://docs.openshift.com/container-platform/4.5/support/troubleshooting/investigating-pod-issues.html\", \"content\": \"Chapter 5.Troubleshooting 5.1.Troubleshooting installations 5.1.1.Determining where installation issues occur When troubleshooting OpenShift Container Platform installation issues, you can monitor installation logs to determine at which stage issues occur. Then, retrieve diagnostic data relevant to that stage. OpenShift Container Platform installation proceeds through the following stages: Ignition configuration files are created. The bootstrap machine boots and starts hosting the remote resources required for the master machines to boot.\", \"score\": 0.4325193, \"raw_content\": null}, {\"title\": \"How do I debug an application that fails to start up? - OKD\", \"url\": \"https://cookbook.openshift.org/logging-monitoring-and-debugging/how-do-i-debug-an-application-that-fails-to-start-up.html\", \"content\": \"The startup messages when oc debug is run will show what the original command was that would have been run for the container. From the shell, you can verify any environment variables or configuration files, change them if necessary, and then run the original command to start your application.\", \"score\": 0.42763633, \"raw_content\": null}, {\"title\": \"Validation and troubleshooting | OpenShift Container Platform | 4.19 ...\", \"url\": \"https://docs.redhat.com/en/documentation/openshift_container_platform/4.19/html-single/validation_and_troubleshooting/index\", \"content\": \"The OpenShift Container Platform installation program contains pinned versions of RHCOS bootimages. Fully automated installations use these pinned artifacts by default. The mirror registry where you downloaded the installation program contains a sha256sum encrypted with the Red Hat product key. For user-provisioned infrastructure installations, you can access information and use the OpenShift\", \"score\": 0.20572707, \"raw_content\": null}]}\u001b[0m\n",
      "\u001b[33minference> \u001b[0m\u001b[33m{\"\u001b[0m\u001b[33mthought\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mI\u001b[0m\u001b[33m found\u001b[0m\u001b[33m several\u001b[0m\u001b[33m search\u001b[0m\u001b[33m results\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m top\u001b[0m\u001b[33m solution\u001b[0m\u001b[33m suggests\u001b[0m\u001b[33m checking\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m container\u001b[0m\u001b[33m and\u001b[0m\u001b[33m verifying\u001b[0m\u001b[33m the\u001b[0m\u001b[33m configuration\u001b[0m\u001b[33m.\u001b[0m\u001b[33m One\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m solutions\u001b[0m\u001b[33m is\u001b[0m\u001b[33m to\u001b[0m\u001b[33m use\u001b[0m\u001b[33m '\u001b[0m\u001b[33moc\u001b[0m\u001b[33m debug\u001b[0m\u001b[33m'\u001b[0m\u001b[33m to\u001b[0m\u001b[33m inspect\u001b[0m\u001b[33m the\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m should\u001b[0m\u001b[33m provide\u001b[0m\u001b[33m a\u001b[0m\u001b[33m summary\u001b[0m\u001b[33m message\u001b[0m\u001b[33m with\u001b[0m\u001b[33m the\u001b[0m\u001b[33m category\u001b[0m\u001b[33m and\u001b[0m\u001b[33m explanation\u001b[0m\u001b[33m of\u001b[0m\u001b[33m the\u001b[0m\u001b[33m error\u001b[0m\u001b[33m.\u001b[0m\u001b[33m The\u001b[0m\u001b[33m error\u001b[0m\u001b[33m is\u001b[0m\u001b[33m '\u001b[0m\u001b[33mContainer\u001b[0m\u001b[33m failed\u001b[0m\u001b[33m due\u001b[0m\u001b[33m to\u001b[0m\u001b[33m an\u001b[0m\u001b[33m unexpected\u001b[0m\u001b[33m issue\u001b[0m\u001b[33m during\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m.'\u001b[0m\u001b[33m Based\u001b[0m\u001b[33m on\u001b[0m\u001b[33m the\u001b[0m\u001b[33m search\u001b[0m\u001b[33m results\u001b[0m\u001b[33m,\u001b[0m\u001b[33m this\u001b[0m\u001b[33m could\u001b[0m\u001b[33m be\u001b[0m\u001b[33m due\u001b[0m\u001b[33m to\u001b[0m\u001b[33m missing\u001b[0m\u001b[33m dependencies\u001b[0m\u001b[33m or\u001b[0m\u001b[33m configuration\u001b[0m\u001b[33m errors\u001b[0m\u001b[33m.\u001b[0m\u001b[33m I\u001b[0m\u001b[33m will\u001b[0m\u001b[33m create\u001b[0m\u001b[33m a\u001b[0m\u001b[33m summary\u001b[0m\u001b[33m message\u001b[0m\u001b[33m.\",\u001b[0m\u001b[33m \"\u001b[0m\u001b[33maction\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m null\u001b[0m\u001b[33m,\u001b[0m\u001b[33m \"\u001b[0m\u001b[33manswer\u001b[0m\u001b[33m\":\u001b[0m\u001b[33m \"\u001b[0m\u001b[33mThe\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m '\u001b[0m\u001b[33mslack\u001b[0m\u001b[33m-test\u001b[0m\u001b[33m'\u001b[0m\u001b[33m in\u001b[0m\u001b[33m the\u001b[0m\u001b[33m '\u001b[0m\u001b[33mtest\u001b[0m\u001b[33m'\u001b[0m\u001b[33m namespace\u001b[0m\u001b[33m encountered\u001b[0m\u001b[33m an\u001b[0m\u001b[33m error\u001b[0m\u001b[33m during\u001b[0m\u001b[33m startup\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Category\u001b[0m\u001b[33m:\u001b[0m\u001b[33m Startup\u001b[0m\u001b[33m Failure\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Explanation\u001b[0m\u001b[33m:\u001b[0m\u001b[33m The\u001b[0m\u001b[33m container\u001b[0m\u001b[33m failed\u001b[0m\u001b[33m due\u001b[0m\u001b[33m to\u001b[0m\u001b[33m an\u001b[0m\u001b[33m unexpected\u001b[0m\u001b[33m issue\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Possible\u001b[0m\u001b[33m causes\u001b[0m\u001b[33m include\u001b[0m\u001b[33m missing\u001b[0m\u001b[33m dependencies\u001b[0m\u001b[33m,\u001b[0m\u001b[33m configuration\u001b[0m\u001b[33m errors\u001b[0m\u001b[33m,\u001b[0m\u001b[33m or\u001b[0m\u001b[33m permission\u001b[0m\u001b[33m issues\u001b[0m\u001b[33m.\u001b[0m\u001b[33m Please\u001b[0m\u001b[33m check\u001b[0m\u001b[33m the\u001b[0m\u001b[33m logs\u001b[0m\u001b[33m and\u001b[0m\u001b[33m configuration\u001b[0m\u001b[33m for\u001b[0m\u001b[33m the\u001b[0m\u001b[33m pod\u001b[0m\u001b[33m.\"\u001b[0m\u001b[33m}\u001b[0m\u001b[97m\u001b[0m\n",
      "\u001b[30m\u001b[0m"
     ]
    }
   ],
   "source": [
    "model_id = \"deepseek-r1-0528-qwen3-8b-bnb-4bit\"\n",
    "stream = True\n",
    "\n",
    "#model_id = \"llama3-2-3b\"\n",
    "#stream = False\n",
    "\n",
    "agent = ReActAgent(\n",
    "            client=client,\n",
    "            model=model_id,\n",
    "            tools=[\"mcp::openshift\", \"builtin::websearch\"],\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": ReActOutput.model_json_schema(),\n",
    "            },\n",
    "            sampling_params={\"max_tokens\":512},\n",
    "        )\n",
    "user_prompts =[\"\"\"Review the OpenShift logs for the pod 'slack-test' with a container of the same name,in the 'test' namespace.\"\n",
    "                If the logs indicate an error search for the top OpenShift solution. Create a summary message with the category and explanation of the error.\"\"\"]\n",
    "session_id = agent.create_session(\"web-session\")\n",
    "for prompt in user_prompts:\n",
    "    print(\"\\n\"+\"=\"*50)\n",
    "    cprint(f\"Processing user query: {prompt}\", \"blue\")\n",
    "    print(\"=\"*50)\n",
    "    response = agent.create_turn(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            }\n",
    "        ],\n",
    "        session_id=session_id,\n",
    "        stream=stream\n",
    "    )\n",
    "    if stream:\n",
    "        for log in EventLogger().log(response):\n",
    "            log.print()\n",
    "    else:\n",
    "        step_printer(response.steps) # print the steps of an agent's response in a formatted way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3998aab7",
   "metadata": {},
   "source": [
    "### Output Analysis\n",
    "\n",
    "Above, we can see that the ReAct agent took nearly an identical approach to the prompt chaining method above, but using a single prompt instead of a chain.  \n",
    "\n",
    "1. First the LLM generated a tool call for the `pods_log` tool included in the **OpenShift MCP server** and fetched the logs for the specified pod.\n",
    "2. The tool successfully retrieved the logs for the pod.\n",
    "3. The LLM  then received the logs from the tool call, along with the original query.\n",
    "4. This context was then passed back to the LLM for the final inference. The inference result provided a summary of the pod logs along with its category of 'Normal' or 'Error'.\n",
    "5. Next the LLM generates a tool call for the default builtin `brave_search` tool which was not available. This is because the models have been trained with Brave Search as a built-in tool.\n",
    "6. Next the LLM generates a tool call for the `web_search` tool instead looking for the top answer to the error.\n",
    "7. A summary of the pod log error and possible next steps to help solve the problem are suggested. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecbc8ab-77c6-48ff-970c-2d5dfd54a2c7",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "This notebook demonstrated how to build an agentic MCP applications with Llama Stack. We did this by initializing an agent with access to two MCP servers that were registered to our Llama Stack server, then invoked the agent on our specified set of queries. We showed that we can do this with more directed Prompt Chaining or with the more open ended ReAct pattern."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
