{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7518dc2-fbeb-4968-b126-af818e32c436",
   "metadata": {},
   "source": [
    "# Introduction to vector databases\n",
    "\n",
    "In this exercise you will learn how vector databases are used to store text. \n",
    "\n",
    "Text is converted to vectors through the use of an `embedding model`. An embedding model is a large language model that is designed to create vectors out of chunks of text. It is these vectors that will be stored in the database.\n",
    "\n",
    "For the lab we will be using Milvus for our vector database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9789051",
   "metadata": {},
   "source": [
    "### Step 1: Setup Environment\n",
    "\n",
    "Install the required Python packages listed in `requirements.txt` to ensure all dependencies for the lab are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08886914",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: Install necessary libraries (run in a cell if needed)\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875c35f",
   "metadata": {},
   "source": [
    "### Step 2: Import Required Libraries\n",
    "\n",
    "The following code block imports all necessary Python libraries and packages that will be used throughout this lab, including Milvus client, embedding model, and analysis tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e9a822-a34d-4755-b954-d76d2bf897f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# Milvus client for vector database operations\n",
    "from pymilvus import connections, utility, Collection, CollectionSchema, FieldSchema, DataType\n",
    "# SentenceTransformer for generating text embeddings\n",
    "from sentence_transformers import SentenceTransformer\n",
    "# Cosine similarity metric for embedding comparison\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# NumPy for numerical computations\n",
    "import numpy as np\n",
    "# Matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "# PCA for dimensionality reduction\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8acfa6d-a20f-4028-ba4c-f6be7cfb39ec",
   "metadata": {},
   "source": [
    "## Create the vector database\n",
    "\n",
    "### Step 3: Create the Vector Database\n",
    "\n",
    "In this step, we will connect to Milvus, define a collection schema, and create a new collection to store our text embeddings. The schema includes an integer ID and a float vector field for the embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac1faa-dd01-43cd-95ff-47ac827222c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Milvus collection name that will store our embeddings\n",
    "collection_name = \"shakeout_collection\"  # Unique identifier for vector store\n",
    "\n",
    "# Establish connection to Milvus vector database service\n",
    "connections.connect(\n",
    "    uri=\"http://milvus-service.milvus.svc.cluster.local:19530\",  # Milvus server endpoint\n",
    "    alias=\"default\"  # Alias to reference this connection in later operations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0597e32f-9e61-48d6-952c-4580f19791f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection list: ['animal_test', 'my_rag_collection']\n"
     ]
    }
   ],
   "source": [
    "# Remove any existing collection with the same name to start fresh\n",
    "if utility.has_collection(collection_name):\n",
    "    utility.drop_collection(collection_name)\n",
    "\n",
    "# Display current collections to verify deletion\n",
    "print(f\"Collection list after cleanup: {utility.list_collections()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d13cc-1884-44a3-a4ab-2b2ed655426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Databases need a schema. In this lab the schema will consist \n",
    "# of an identifier and a vector that contains the embedding of a text string.\n",
    "\n",
    "# Define the primary key field for unique record identification\n",
    "id_field = FieldSchema(\n",
    "    name=\"id\",\n",
    "    dtype=DataType.INT64,\n",
    "    is_primary=True,\n",
    "    auto_id=False\n",
    ")\n",
    "\n",
    "# Specify embedding model and its output dimension\n",
    "embedding_model = \"all-MiniLM-L6-v2\"  # Example Hugging Face model\n",
    "embedding_dim = 384  # Embedding vector size as per the model\n",
    "\n",
    "# Define the vector field to hold embedding values\n",
    "embedding_field = FieldSchema(\n",
    "    name=\"embedding\",\n",
    "    dtype=DataType.FLOAT_VECTOR,\n",
    "    dim=embedding_dim\n",
    ")\n",
    "\n",
    "# Assemble collection schema combining ID and embedding fields\n",
    "schema = CollectionSchema(\n",
    "    fields=[id_field, embedding_field],\n",
    "    description=\"Milvus shakeout test\",\n",
    "    enable_dynamic_field=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1594974-484a-4b48-bbfc-4166f393d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection: {'auto_id': False, 'description': 'Milvus shakeout test', 'fields': [{'name': 'id', 'description': '', 'type': <DataType.INT64: 5>, 'is_primary': True, 'auto_id': False}, {'name': 'embedding', 'description': '', 'type': <DataType.FLOAT_VECTOR: 101>, 'params': {'dim': 384}}], 'enable_dynamic_field': False}\n",
      "\n",
      "Collection list: ['my_rag_collection', 'animal_test', 'shakeout_collection']\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the Milvus collection using the defined schema and configuration\n",
    "collection = Collection(\n",
    "    name=collection_name, \n",
    "    schema=schema, \n",
    "    using='default', \n",
    "    shards_num=2,\n",
    "    consistency_level=\"Strong\"\n",
    ")\n",
    "\n",
    "# Display the collection schema that was just created\n",
    "print(f\"Collection: {collection.schema}\\n\")\n",
    "\n",
    "# List all collections in Milvus to confirm creation\n",
    "print(f\"Collection list: {utility.list_collections()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a43ec4-519d-4ef3-921e-969d55858f0e",
   "metadata": {},
   "source": [
    "## Create test data for the vector database\n",
    "\n",
    "### Step 4: Generate Embeddings and Create Test Data\n",
    "\n",
    "In this step, we use a Hugging Face embedding model to convert text terms into high-dimensional vectors that will be stored in the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a6ccd-6c07-494c-b412-25f8d435a515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding for 'dog' (first 5 values):\n",
      "[-0.053147    0.0141944   0.00714573  0.06860867 -0.07848035]\n",
      "\n",
      "Embedding for 'cat' (first 5 values):\n",
      "[ 0.03733037  0.05116179 -0.00030609  0.06020984 -0.11749443]\n",
      "\n",
      "Embedding for 'pumpkin' (first 5 values):\n",
      "[ 0.00623484  0.02070913 -0.05396153  0.05416825 -0.01124374]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings using a simple embedding model from Hugging Face \n",
    "model = SentenceTransformer(embedding_model)\n",
    "\n",
    "# We will put three words into the database and hope to see how the vector database uses the \n",
    "# embedding model to store these in a way where we can find the most similar words (cat and dog)\n",
    "terms = [\"dog\", \"cat\", \"pumpkin\"]\n",
    "embeddings = model.encode(terms)\n",
    "\n",
    "# Display the first 5 rows of embedding data. Observe that these are now vectors.\n",
    "for term, vector in zip(terms, embeddings):\n",
    "    print(f\"Embedding for '{term}' (first 5 values):\\n{vector[:5]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8736613a-b702-42e5-ab99-901b0e4ed823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a \"list of dictionaries\" data structure that matches the schema we defined for the vector database. E.g.\n",
    "# [\n",
    "#    {\"id\": 0, \"embedding\": [0.1, 0.2, ...]},\n",
    "#    {\"id\": 1, \"embedding\": [0.3, 0.4, ...]},\n",
    "#    {\"id\": 2, \"embedding\": [0.6, 0.2, ...]}\n",
    "#]\n",
    "data = [\n",
    "    {\"id\": i, \"embedding\": vec}\n",
    "    for i, vec in enumerate(embeddings.tolist())\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3b6fd94-63d9-4caf-bb5e-b5f3e7f54315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 3, delete count: 0, upsert count: 0, timestamp: 459173881894928388, success count: 3, err count: 0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert the vectors into the collection\n",
    "collection.insert(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f41ad3ed-97fe-4737-ac52-8e4e876f2eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create index on the vector field\n",
    "collection.create_index(\n",
    "    field_name=\"embedding\",\n",
    "    index_params={\n",
    "        \"metric_type\": \"COSINE\",\n",
    "        \"index_type\": \"IVF_FLAT\",\n",
    "        \"params\": {\"nlist\": 128}\n",
    "    },\n",
    "    index_name=\"idx\"\n",
    ")\n",
    "\n",
    "\n",
    "collection.flush()\n",
    "collection.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e078f59-518f-4203-af5a-f9b4738140e0",
   "metadata": {},
   "source": [
    "## Test data retrieval\n",
    "\n",
    "### Step 5: Test Data Retrieval\n",
    "\n",
    "In this step, we define a function to search the collection using an embedding and retrieve the most similar items based on cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb64183-86b1-4164-87bd-59993ae9abd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: data: [\"['id: 0, distance: 0.9999999403953552, entity: {}', 'id: 1, distance: 0.6606375575065613, entity: {}', 'id: 2, distance: 0.3701188564300537, entity: {}']\"]\n"
     ]
    }
   ],
   "source": [
    "# Prove we can retrieve data from the database\n",
    "def search(term):\n",
    "    vector = model.encode([term])\n",
    "    results = collection.search(vector, \"embedding\", param={\"metric_type\": \"COSINE\"}, limit=3)\n",
    "    return results\n",
    "\n",
    "results_dog = search(\"dog\")\n",
    "print(f\"Results: {results_dog}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bec5441-cb79-4387-bdcb-6429c3e8eae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity (dog vs cat): 0.6606376\n",
      "Similarity (dog vs pumpkin): 0.37011895\n"
     ]
    }
   ],
   "source": [
    "# Perform a cosine similarity search to find how similar dog (embeddings[0]) is to cat and pumpkin (embeddings[1:]).\n",
    "cos_sim = cosine_similarity([embeddings[0]], embeddings[1:])\n",
    "\n",
    "print(\"Similarity (dog vs cat):\", cos_sim[0][0])\n",
    "print(\"Similarity (dog vs pumpkin):\", cos_sim[0][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b468105",
   "metadata": {},
   "source": [
    "### Step 6: Visualize Embeddings\n",
    "\n",
    "Here we reduce the high-dimensional embeddings to 2D using PCA and plot the terms to observe their relative positions and relationships.\n",
    "\n",
    "Observe that dog and cat are more similar than dog and pumpkin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf70090-b150-4d0d-86be-c35c15bcefcf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PCA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Visualise the result\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m pca = \u001b[43mPCA\u001b[49m(n_components=\u001b[32m2\u001b[39m)\n\u001b[32m      3\u001b[39m reduced = pca.fit_transform(embeddings)\n\u001b[32m      4\u001b[39m plt.scatter(reduced[:, \u001b[32m0\u001b[39m], reduced[:, \u001b[32m1\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'PCA' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualise the result\n",
    "pca = PCA(n_components=2)\n",
    "reduced = pca.fit_transform(embeddings)\n",
    "plt.scatter(reduced[:, 0], reduced[:, 1])\n",
    "for i, term in enumerate(terms):\n",
    "    plt.annotate(term, (reduced[i, 0], reduced[i, 1]))\n",
    "plt.title(\"PCA Projection of Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fc69d4-7c1a-43f6-80c3-fe47edf2718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Milvus connection\n",
    "collection.release()\n",
    "utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a5dd78-19f6-44bb-ad70-a3ced0ef081f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
